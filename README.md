# AdAdaGrad 

This is an anonymous repository containing figures for rebuttal of the manuscript AdAdaGrad: Adaptive Batch Size Schemes for Adaptive Gradient Methods. 

We perform additional experiments to supplement and justify our claims in the paper and the rebuttal. 

1. `adadagrad_cnn_mnist_final.png`: Figure 2 in the paper (Appendix C.2), comparing across AdAdaGrad, AdAdaGradNorm and AdaSGD, i.e., AdaGrad, AdaGradNorm and SGD with adaptive batch sizes

2. `adadagrad_cnn_mnist_rebuttal_1.png`: Comparing AdaGrad (with constant batch sizes) to AdAdaGrad (i.e., AdaGrad with adaptive batch sizes)

3. `adadagrad_cnn_mnist_rebuttal_2.png`: Comparing AdaSGD (with constant batch sizes) to AdaSGD (i.e., SGD with adaptive batch sizes)

4. `adadagrad_cnn_mnist_rebuttal_3.png`: Comparing AdaSGD and AdAdaGradNorm using only the inner product test and using the augmented inner product test (i.e., when both the inner product test and the orthogonality test are used)

